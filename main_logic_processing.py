from ast import parse
import json
import os
import time
import argparse
from typing import Dict, Any, Optional
from webbrowser import get
from disk_info import DiskManager

import disk_info
from partition_disk import initialize_disk_to_gpt
from partition_disk import initialize_disk_to_partitioning_C
from partition_disk import initialize_disk_to_partitioning_D
from partition_disk import initialize_disk_to_partitioning_E
from call_ghost import call_ghost
from call_bcdboot import repair_boot_loader

# JSONé…ç½®ç¼“å­˜ - è¿™ä¸ªä¿ç•™ï¼Œå› ä¸ºå®ƒæ˜¯çœŸæ­£çš„ç¼“å­˜æœºåˆ¶
_JSON_CACHE = {}
_JSON_CACHE_TIME = {}
def parse_arguments():
    parser = argparse.ArgumentParser(
    description="ç£ç›˜ä¿¡æ¯æŸ¥è¯¢å·¥å…·",
    epilog="ç¤ºä¾‹: python main.py --disk 3 æˆ– python main.py -d 5 --json config.json"
    )
    
    # æ·»åŠ ç£ç›˜ç¼–å·å‚æ•°
    parser.add_argument(
    '--disk', '-d',
    type=int,
    required=True,
    choices=[1, 2, 3, 4, 5, 6],
    help='ç£ç›˜ç¼–å· (1-6)ï¼Œç”¨äºæŒ‡å®šè¦æ“ä½œçš„ç£ç›˜',
    metavar='DISK_NUMBER'
    )
    
    parser.add_argument(
    '--json', '-j',
    type=str,
    required=True,
    help='JSONé…ç½®æ–‡ä»¶è·¯å¾„',
    metavar='FILE_PATH'
    )
    
    return parser.parse_args()



number_list = [
    {
        "disk_number": 1,
        "efi_letter": "E",
        "c_letter": "F",
        "d_letter": "G",
        "e_letter": "H",
    },
    {
        "disk_number": 2,
        "efi_letter": "I",
        "c_letter": "J",
        "d_letter": "K",
        "e_letter": "L",
    },
    {
        "disk_number": 3,
        "efi_letter": "M",
        "c_letter": "N",
        "d_letter": "O",
        "e_letter": "P",
    },
    {
        "disk_number": 4,
        "efi_letter": "Q",
        "c_letter": "R",
        "d_letter": "S",
        "e_letter": "T",
    },
    {
        "disk_number": 5,
        "efi_letter": "U",
        "c_letter": "V",
        "d_letter": "W",
        "e_letter": "X",
    },
    {
        "disk_number": 6,
        "efi_letter": "Y",
        "c_letter": "Z",
        "d_letter": "A",
        "e_letter": "B",
    },
]

def get_config_value(config_data: Dict[str, Any], key_path: str, default: Any = None) -> Any:
    """
    å®‰å…¨è·å–é…ç½®å€¼çš„å‡½æ•°
    
    Args:
        config_data: JSONé…ç½®æ•°æ®å­—å…¸
        key_path: æ”¯æŒç‚¹åˆ†éš”çš„è·¯å¾„ï¼Œå¦‚ 'disk.number'
        default: é»˜è®¤å€¼
        
    Returns:
        é…ç½®å€¼æˆ–é»˜è®¤å€¼
    """
    if not config_data:
        return default
    
    # å¤„ç†ç®€å•çš„é”®è®¿é—®
    if '.' not in key_path:
        return config_data.get(key_path, default)
    
    # å¤„ç†åµŒå¥—è·¯å¾„è®¿é—®
    keys = key_path.split('.')
    current = config_data
    
    try:
        for key in keys:
            if isinstance(current, dict) and key in current:
                current = current[key]
            else:
                return default
        return current if current is not None else default
    except (TypeError, KeyError, AttributeError):
        return default


def clear_json_cache():
    """æ¸…ç©ºJSONé…ç½®ç¼“å­˜"""
    global _JSON_CACHE, _JSON_CACHE_TIME
    _JSON_CACHE.clear()
    _JSON_CACHE_TIME.clear()
    print("JSONç¼“å­˜å·²æ¸…ç©º")


def get_cache_info() -> Dict[str, Any]:
    """
    è·å–ç¼“å­˜ä¿¡æ¯
    
    Returns:
        ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
    """
    total_size = 0
    for filepath in _JSON_CACHE.keys():
        if os.path.exists(filepath):
            try:
                total_size += os.path.getsize(filepath)
            except (OSError, IOError):
                pass  # å¿½ç•¥æ— æ³•è®¿é—®çš„æ–‡ä»¶
    
    return {
        "cached_files": len(_JSON_CACHE),
        "cache_size_mb": total_size / (1024 * 1024),
        "validation_enabled": False,  # JSONç»“æ„éªŒè¯åŠŸèƒ½å·²è¢«ç¦ç”¨
        "cache_keys": list(_JSON_CACHE.keys())
    }


def _validate_json_file_path(file_path: str) -> str:
    """éªŒè¯å¹¶å¤„ç†JSONæ–‡ä»¶è·¯å¾„
    
    Args:
        file_path: JSONæ–‡ä»¶è·¯å¾„
        
    Returns:
        å¤„ç†åçš„ç»å¯¹è·¯å¾„
        
    Raises:
        FileNotFoundError: æ–‡ä»¶ä¸å­˜åœ¨
        ValueError: æ–‡ä»¶ä¸ºç©ºæˆ–è¿‡å¤§
    """
    abs_path = os.path.abspath(file_path)
    
    if not os.path.exists(abs_path):
        raise FileNotFoundError(f"JSONæ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
    
    file_size = os.path.getsize(abs_path)
    if file_size == 0:
        raise ValueError("JSONæ–‡ä»¶ä¸ºç©º")
    elif file_size > 50 * 1024 * 1024:  # 50MBé™åˆ¶
        raise ValueError(f"JSONæ–‡ä»¶è¿‡å¤§: {file_size / (1024*1024):.2f}MB")
    
    return abs_path


def _check_cache(abs_path: str) -> Optional[Dict[str, Any]]:
    """æ£€æŸ¥ç¼“å­˜
    
    Args:
        abs_path: æ–‡ä»¶ç»å¯¹è·¯å¾„
        
    Returns:
        ç¼“å­˜çš„æ•°æ®ï¼Œå¦‚æœç¼“å­˜æœªå‘½ä¸­åˆ™è¿”å›None
    """
    if abs_path in _JSON_CACHE and abs_path in _JSON_CACHE_TIME:
        file_mtime = os.path.getmtime(abs_path)
        if _JSON_CACHE_TIME[abs_path] == file_mtime:
            print(f"ä»ç¼“å­˜è¯»å–JSONé…ç½®: {abs_path}")
            return _JSON_CACHE[abs_path]
    return None


def _read_and_parse_json(abs_path: str, max_retries: int = 3) -> Dict[str, Any]:
    """è¯»å–å¹¶è§£æJSONæ–‡ä»¶
    
    Args:
        abs_path: æ–‡ä»¶ç»å¯¹è·¯å¾„
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        
    Returns:
        è§£æåçš„JSONæ•°æ®
        
    Raises:
        json.JSONDecodeError: JSONè§£æé”™è¯¯
        ValueError: æ–‡ä»¶å†…å®¹ä¸ºç©ºæˆ–æ— æ•ˆ
    """
    for attempt in range(max_retries):
        try:
            with open(abs_path, 'r', encoding='utf-8') as file:
                content = file.read()
                
            if not content.strip():
                raise ValueError("JSONæ–‡ä»¶å†…å®¹ä¸ºç©ºæˆ–åªåŒ…å«ç©ºç™½å­—ç¬¦")
            
            return json.loads(content)
            
        except json.JSONDecodeError as e:
            if attempt == max_retries - 1:
                raise
            print(f"JSONè§£æé‡è¯• {attempt + 1}/{max_retries}: {e}")
            time.sleep(0.1)


def _update_cache(abs_path: str, config_data: Dict[str, Any]) -> None:
    """æ›´æ–°ç¼“å­˜
    
    Args:
        abs_path: æ–‡ä»¶ç»å¯¹è·¯å¾„
        config_data: é…ç½®æ•°æ®
    """
    _JSON_CACHE[abs_path] = config_data
    _JSON_CACHE_TIME[abs_path] = os.path.getmtime(abs_path)


def read_json_config(json_file_path: str, use_cache: bool = True, 
                    validate_schema: bool = True) -> Optional[Dict[str, Any]]:
    """
    é«˜æ€§èƒ½è¯»å–å¹¶è§£æJSONé…ç½®æ–‡ä»¶
    
    ä¸»è¦åŠŸèƒ½ï¼š
    1. è¯»å–JSONé…ç½®æ–‡ä»¶
    2. éªŒè¯æ–‡ä»¶æ ¼å¼å’Œç»“æ„
    3. æ”¯æŒç¼“å­˜æœºåˆ¶æé«˜æ€§èƒ½
    4. æä¾›è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯å’Œå¤„ç†
    
    Args:
        json_file_path: JSONæ–‡ä»¶è·¯å¾„
        use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜æœºåˆ¶ï¼ˆé¿å…é‡å¤è¯»å–åŒä¸€æ–‡ä»¶ï¼‰
        validate_schema: æ˜¯å¦è¿›è¡ŒschemaéªŒè¯ï¼ˆæ£€æŸ¥JSONç»“æ„æ˜¯å¦ç¬¦åˆé¢„æœŸï¼‰
        
    Returns:
        è§£æåçš„JSONæ•°æ®ï¼Œå¤±è´¥æ—¶è¿”å›None
    """
    try:
        # éªŒè¯æ–‡ä»¶è·¯å¾„
        abs_path = _validate_json_file_path(json_file_path)
        
        # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
        if not abs_path.lower().endswith(('.json', '.jsonc', '.json5')):
            print(f"è­¦å‘Š: æ–‡ä»¶æ‰©å±•åä¸æ˜¯æ ‡å‡†çš„JSONæ ¼å¼: {json_file_path}")
        
        # æ£€æŸ¥ç¼“å­˜
        if use_cache:
            cached_data = _check_cache(abs_path)
            if cached_data is not None:
                return cached_data
        
        # è¯»å–å¹¶è§£æJSON
        config_data = _read_and_parse_json(abs_path)
        
        # æ›´æ–°ç¼“å­˜
        if use_cache:
            _update_cache(abs_path, config_data)
        
        # æ˜¾ç¤ºæˆåŠŸä¿¡æ¯
        if config_data and 'description' in config_data:
            print(f"æˆåŠŸè¯»å–JSONé…ç½®æ–‡ä»¶: {config_data['description']}")
        else:
            print(f"æˆåŠŸè¯»å–JSONé…ç½®æ–‡ä»¶: {json_file_path}")
        
        return config_data
        
    except FileNotFoundError as e:
        print(f"X æ–‡ä»¶é”™è¯¯: {e}")
        return None
    except json.JSONDecodeError as e:
        print(f"X JSONæ ¼å¼é”™è¯¯: {e}")
        print("   å»ºè®®æ£€æŸ¥:")
        print("   - å­—ç¬¦ä¸²æ˜¯å¦ç”¨åŒå¼•å·åŒ…å›´")
        print("   - æœ«å°¾é€—å·å’Œä¸å¿…è¦çš„é€—å·")
        print("   - è½¬ä¹‰å­—ç¬¦æ˜¯å¦æ­£ç¡®")
        return None
    except ValueError as e:
        print(f"X æ–‡ä»¶éªŒè¯é”™è¯¯: {e}")
        return None
    except PermissionError as e:
        print(f"X æƒé™é”™è¯¯: æ— æ³•è¯»å–æ–‡ä»¶ {json_file_path}")
        return None
    except Exception as e:
        print(f"X è¯»å–JSONæ–‡ä»¶æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        return None


def analyze_json_structure(data: Any, max_depth: int = 3, current_depth: int = 0):
    """
    åˆ†æå¹¶æ˜¾ç¤ºJSONæ•°æ®ç»“æ„
    
    Args:
        data: JSONæ•°æ®
        max_depth: æœ€å¤§åˆ†ææ·±åº¦
        current_depth: å½“å‰åˆ†ææ·±åº¦
    """
    if current_depth >= max_depth:
        return
    
    indent = "  " * current_depth
    
    if isinstance(data, dict):
        print(f"{indent}ğŸ“Š å­—å…¸ç»“æ„ - {len(data)} ä¸ªé”®å€¼å¯¹:")
        
        # æ˜¾ç¤ºä¸»è¦é”®å€¼
        keys = list(data.keys())
        main_keys = keys[:5] if len(keys) > 5 else keys
        
        for key in main_keys:
            value = data[key]
            value_type = type(value).__name__
            if isinstance(value, str):
                preview = value[:20] + "..." if len(value) > 20 else value
                print(f"{indent}  ğŸ”‘ {key}: {value_type} = {repr(preview)}")
            elif isinstance(value, (int, float)):
                print(f"{indent}  ğŸ”¢ {key}: {value_type} = {value}")
            elif isinstance(value, list):
                print(f"{indent}  ğŸ“‹ {key}: {value_type}[{len(value)}]")
            elif isinstance(value, dict):
                print(f"{indent}  ğŸ“ {key}: {value_type}[{len(value)}]")
            else:
                print(f"{indent}  æ³¨é‡Š {key}: {value_type}")
        
        if len(keys) > 5:
            print(f"{indent}  ... è¿˜æœ‰ {len(keys) - 5} ä¸ªå…¶ä»–é”®å€¼")
            
        # é€’å½’åˆ†æåµŒå¥—ç»“æ„ï¼ˆé™åˆ¶æ·±åº¦ï¼‰
        if current_depth < max_depth - 1:
            nested_dicts = [v for v in data.values() if isinstance(v, dict) and len(v) > 0]
            for i, nested_data in enumerate(nested_dicts[:2]):  # åªæ˜¾ç¤ºå‰2ä¸ªåµŒå¥—ç»“æ„
                print(f"{indent}  ğŸ“‚ åµŒå¥—å­—å…¸ {i+1}:")
                analyze_json_structure(nested_data, max_depth, current_depth + 2)
                
    elif isinstance(data, list):
        print(f"{indent}ğŸ“‹ åˆ—è¡¨ç»“æ„ - {len(data)} ä¸ªå…ƒç´ :")
        if data:
            sample_item = data[0]
            sample_type = type(sample_item).__name__
            print(f"{indent}  å…ƒç´ ç±»å‹: {sample_type}")
            
            # å¦‚æœæ˜¯å­—å…¸åˆ—è¡¨ï¼Œæ˜¾ç¤ºé”®å€¼
            if isinstance(sample_item, dict) and sample_item:
                sample_keys = list(sample_item.keys())[:3]
                print(f"{indent}  ä¸»è¦é”®å€¼: {', '.join(sample_keys)}")
    else:
        print(f"{indent}æ³¨é‡Š {type(data).__name__}: {data}")


def setup_json_config(args: argparse.Namespace) -> Dict[str, Any]:
    """è®¾ç½®å¹¶è¯»å–JSONé…ç½®æ–‡ä»¶
    
    Args:
        args: å‘½ä»¤è¡Œå‚æ•°å¯¹è±¡ï¼ŒåŒ…å«jsonå­—æ®µ
        
    Returns:
        è¯»å–çš„JSONé…ç½®æ•°æ®å­—å…¸ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å›ç©ºå­—å…¸
    """
    if args.json:
        config_data = read_json_config(args.json)
        if config_data is None:
            print("X JSONé…ç½®æ–‡ä»¶è¯»å–å¤±è´¥ï¼Œç¨‹åºé€€å‡ºã€‚")
            return {}
        else:
            return config_data
    else:
        print("â„¹ï¸  æœªæŒ‡å®šJSONé…ç½®æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤é…ç½®ã€‚")
        return {}


def validate_protected_disk(disk_number: int, config_data: Optional[dict] = None) -> bool:
    """
    éªŒè¯ç”¨æˆ·è¾“å…¥çš„disk_numberæ˜¯å¦ä¸ºä¿æŠ¤ç¡¬ç›˜
    
    Args:
        disk_number: ç£ç›˜ç¼–å· (1-6)
        config_data: JSONé…ç½®æ•°æ®å­—å…¸ï¼ŒåŒ…å«excluded_disk_nameså­—æ®µ
        
    Returns:
        bool: å¦‚æœä¸æ˜¯ä¿æŠ¤ç¡¬ç›˜è¿”å›Trueï¼Œå¦‚æœæ˜¯ä¿æŠ¤ç¡¬ç›˜è¿”å›False
        
    Raises:
        ValueError: å½“disk_numberè¶…å‡ºèŒƒå›´æˆ–é…ç½®æ•°æ®æ— æ•ˆæ—¶æŠ›å‡º
        RuntimeError: å½“æ— æ³•è·å–ç£ç›˜ä¿¡æ¯æ—¶æŠ›å‡º
    """
    if not isinstance(disk_number, int) or disk_number < 1 or disk_number > 6:
        raise ValueError(f"ç£ç›˜ç¼–å·å¿…é¡»åœ¨1-6èŒƒå›´å†…ï¼Œé”™è¯¯ç¼–å·: {disk_number}")
    
    # å¦‚æœæ²¡æœ‰æä¾›é…ç½®æ•°æ®ï¼Œè¿”å›Trueï¼ˆé»˜è®¤å¯æ“ä½œï¼‰
    if config_data is None:
        return True
    
    # è·å–ä¿æŠ¤ç¡¬ç›˜åç§°åˆ—è¡¨
    excluded_disk_names = config_data.get('excluded_disk_names', [])
    if not isinstance(excluded_disk_names, list):
        raise ValueError("excluded_disk_nameså¿…é¡»æ˜¯åˆ—è¡¨æ ¼å¼")
    
    try:
        # ä½¿ç”¨disk_infoæ¨¡å—æŸ¥è¯¢æŒ‡å®šç£ç›˜ç¼–å·çš„ç¡¬ç›˜åç§°
        disk_manager = DiskManager()
        disk_info = disk_manager.get_disk_by_index(disk_number)
        
        if disk_info is None:
            raise RuntimeError(f"æœªæ‰¾åˆ°ç£ç›˜ç¼–å· {disk_number} çš„ä¿¡æ¯")
        
        disk_name = disk_info.name
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºä¿æŠ¤ç¡¬ç›˜
        if disk_name in excluded_disk_names:
            print(f"âš ï¸  ç£ç›˜ {disk_number} ({disk_name}) æ˜¯ä¿æŠ¤ç¡¬ç›˜ï¼Œæ— æ³•æ“ä½œ")
            return False
        else:
            # éªŒè¯æˆåŠŸï¼Œé™é»˜è¿”å›ï¼ˆä¸è¾“å‡ºä»»ä½•ä¿¡æ¯ï¼‰
            return True
            
    except Exception as e:
        raise RuntimeError(f"è·å–ç£ç›˜ {disk_number} ä¿¡æ¯å¤±è´¥: {e}")



def get_disk_letter(disk_number, letter_type):
    """
    è·å–æŒ‡å®šç£ç›˜çš„ç‰¹å®šåˆ†åŒºå­—æ¯
    
    Args:
        disk_number: ç£ç›˜ç¼–å· (1-6)
        letter_type: åˆ†åŒºç±»å‹ ('efi', 'c', 'd', 'e')
    
    Returns:
        str: å¯¹åº”çš„åˆ†åŒºå­—æ¯ï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å›None
        
    Example:
        >>> get_disk_letter(3, 'efi')
        'M'
    """
    for disk_config in number_list:
        if disk_config["disk_number"] == disk_number:
            if letter_type == 'efi':
                return disk_config["efi_letter"]
            elif letter_type == 'c':
                return disk_config["c_letter"]
            elif letter_type == 'd':
                return disk_config["d_letter"]
            elif letter_type == 'e':
                return disk_config["e_letter"]
            else:
                return None
    return None




def all_disk_partitions(disk_number, efi_size, c_size):
    """
    åˆå§‹åŒ–ç£ç›˜åˆ†åŒº
    
    Args:
        disk_number: ç£ç›˜ç¼–å· (1-6)
        efi_size: EFIåˆ†åŒºå¤§å° (MB)
        c_size: Cç›˜åˆ†åŒºå¤§å° (MB)
    """
    efi_letter = get_disk_letter(disk_number, 'efi')
    c_letter = get_disk_letter(disk_number, 'c')
    d_letter = get_disk_letter(disk_number, 'd')
    e_letter = get_disk_letter(disk_number, 'e')

    # é¡ºåºæ‰§è¡Œï¼šç¬¬ä¸€æ­¥
    if not initialize_disk_to_gpt(disk_number, efi_size, efi_letter):
        return False
    
    # é¡ºåºæ‰§è¡Œï¼šç¬¬äºŒæ­¥
    if not initialize_disk_to_partitioning_C(disk_number, c_size, c_letter):
        return False
    
    # é¡ºåºæ‰§è¡Œï¼šç¬¬ä¸‰æ­¥
    if not initialize_disk_to_partitioning_D(disk_number, d_letter, efi_size, c_size):
        return False
    
    # é¡ºåºæ‰§è¡Œï¼šç¬¬å››æ­¥
    if not initialize_disk_to_partitioning_E(disk_number, e_letter):
        return False
    
    return True



if __name__ == "__main__":
    
    args = parse_arguments()
    disk_number = args.disk
    json_data = setup_json_config(args)
    efi_size = json_data.get("efi_size")
    c_size = json_data.get("c_size")
    gho_exe = json_data.get("gho_exe")
    win_gho = json_data.get("win_gho")
    bcd_exe = json_data.get("bcd_exe")
    efi_letter = get_disk_letter(disk_number, 'efi')
    c_letter = get_disk_letter(disk_number, 'c')
    print(c_letter)
    print(c_size)
    print(efi_size)
    print(disk_number)
    
    validate_protected_disk(disk_number, json_data)

        # if all_disk_partitions(disk_number, efi_size, c_size):
        #     time.sleep(5)
        #     if call_ghost(disk_number, gho_exe, win_gho, c_letter):
        #         time.sleep(5)
        #         if repair_boot_loader(disk_number, bcd_exe, efi_letter, c_letter):
        #             pass
        #         else:
        #             pass
        #     else:
        #         pass
        # else:
        #     pass


